{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN mountaincar - main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Failed to complete in trial 0\n",
      "Failed to complete in trial 1\n",
      "Failed to complete in trial 2\n",
      "Failed to complete in trial 3\n",
      "Failed to complete in trial 4\n",
      "Failed to complete in trial 5\n",
      "Failed to complete in trial 6\n",
      "Failed to complete in trial 7\n",
      "Failed to complete in trial 8\n",
      "Failed to complete in trial 9\n",
      "Failed to complete in trial 10\n",
      "Failed to complete in trial 11\n",
      "Failed to complete in trial 12\n",
      "Failed to complete in trial 13\n",
      "Failed to complete in trial 14\n",
      "Failed to complete in trial 15\n",
      "Failed to complete in trial 16\n",
      "Failed to complete in trial 17\n",
      "Failed to complete in trial 18\n",
      "Failed to complete in trial 19\n",
      "Failed to complete in trial 20\n",
      "Failed to complete in trial 21\n",
      "Failed to complete in trial 22\n",
      "Failed to complete in trial 23\n",
      "Failed to complete in trial 24\n",
      "Failed to complete in trial 25\n",
      "Failed to complete in trial 26\n",
      "Failed to complete in trial 27\n",
      "Failed to complete in trial 28\n",
      "Failed to complete in trial 29\n",
      "Failed to complete in trial 30\n",
      "Failed to complete in trial 31\n",
      "Failed to complete in trial 32\n",
      "Failed to complete in trial 33\n",
      "Failed to complete in trial 34\n",
      "Failed to complete in trial 35\n",
      "Failed to complete in trial 36\n",
      "Failed to complete in trial 37\n",
      "Failed to complete in trial 38\n",
      "Failed to complete in trial 39\n",
      "Failed to complete in trial 40\n",
      "Failed to complete in trial 41\n",
      "Failed to complete in trial 42\n",
      "Failed to complete in trial 43\n",
      "Failed to complete in trial 44\n",
      "Failed to complete in trial 45\n",
      "Failed to complete in trial 46\n",
      "Failed to complete in trial 47\n",
      "Failed to complete in trial 48\n",
      "Failed to complete in trial 49\n",
      "Failed to complete in trial 50\n",
      "Failed to complete in trial 51\n",
      "Failed to complete in trial 52\n",
      "Failed to complete in trial 53\n",
      "Failed to complete in trial 54\n",
      "Failed to complete in trial 55\n",
      "Failed to complete in trial 56\n",
      "Failed to complete in trial 57\n",
      "Completed in 58 trials\n",
      "Failed to complete in trial 59\n",
      "Failed to complete in trial 60\n",
      "Failed to complete in trial 61\n",
      "Failed to complete in trial 62\n",
      "Failed to complete in trial 63\n",
      "Failed to complete in trial 64\n",
      "Failed to complete in trial 65\n",
      "Failed to complete in trial 66\n",
      "Failed to complete in trial 67\n",
      "Failed to complete in trial 68\n",
      "Failed to complete in trial 69\n",
      "Completed in 70 trials\n",
      "Failed to complete in trial 71\n",
      "Failed to complete in trial 72\n",
      "Completed in 73 trials\n",
      "Failed to complete in trial 74\n",
      "Failed to complete in trial 75\n",
      "Failed to complete in trial 76\n",
      "Failed to complete in trial 77\n",
      "Failed to complete in trial 78\n",
      "Failed to complete in trial 79\n",
      "Failed to complete in trial 80\n",
      "Failed to complete in trial 81\n",
      "Failed to complete in trial 82\n",
      "Failed to complete in trial 83\n",
      "Failed to complete in trial 84\n",
      "Failed to complete in trial 85\n",
      "Failed to complete in trial 86\n",
      "Failed to complete in trial 87\n",
      "Failed to complete in trial 88\n",
      "Failed to complete in trial 89\n",
      "Failed to complete in trial 90\n",
      "Failed to complete in trial 91\n",
      "Failed to complete in trial 92\n",
      "Failed to complete in trial 93\n",
      "Failed to complete in trial 94\n",
      "Failed to complete in trial 95\n",
      "Failed to complete in trial 96\n",
      "Failed to complete in trial 97\n",
      "Failed to complete in trial 98\n",
      "Failed to complete in trial 99\n",
      "Completed in 100 trials\n",
      "Failed to complete in trial 101\n",
      "Failed to complete in trial 102\n",
      "Completed in 103 trials\n",
      "Failed to complete in trial 104\n",
      "Failed to complete in trial 105\n",
      "Failed to complete in trial 106\n",
      "Failed to complete in trial 107\n",
      "Failed to complete in trial 108\n",
      "Failed to complete in trial 109\n",
      "Failed to complete in trial 110\n",
      "Failed to complete in trial 111\n",
      "Failed to complete in trial 112\n",
      "Failed to complete in trial 113\n",
      "Failed to complete in trial 114\n",
      "Failed to complete in trial 115\n",
      "Failed to complete in trial 116\n",
      "Failed to complete in trial 117\n",
      "Failed to complete in trial 118\n",
      "Failed to complete in trial 119\n",
      "Failed to complete in trial 120\n",
      "Failed to complete in trial 121\n",
      "Failed to complete in trial 122\n",
      "Failed to complete in trial 123\n",
      "Failed to complete in trial 124\n",
      "Failed to complete in trial 125\n",
      "Failed to complete in trial 126\n",
      "Failed to complete in trial 127\n",
      "Failed to complete in trial 128\n",
      "Failed to complete in trial 129\n",
      "Failed to complete in trial 130\n",
      "Failed to complete in trial 131\n",
      "Failed to complete in trial 132\n",
      "Failed to complete in trial 133\n",
      "Failed to complete in trial 134\n",
      "Failed to complete in trial 135\n",
      "Failed to complete in trial 136\n",
      "Failed to complete in trial 137\n",
      "Failed to complete in trial 138\n",
      "Failed to complete in trial 139\n",
      "Failed to complete in trial 140\n",
      "Failed to complete in trial 141\n",
      "Failed to complete in trial 142\n",
      "Failed to complete in trial 143\n",
      "Failed to complete in trial 144\n",
      "Failed to complete in trial 145\n",
      "Failed to complete in trial 146\n",
      "Failed to complete in trial 147\n",
      "Failed to complete in trial 148\n",
      "Failed to complete in trial 149\n",
      "Failed to complete in trial 150\n",
      "Failed to complete in trial 151\n",
      "Failed to complete in trial 152\n",
      "Failed to complete in trial 153\n",
      "Failed to complete in trial 154\n",
      "Failed to complete in trial 155\n",
      "Failed to complete in trial 156\n",
      "Failed to complete in trial 157\n",
      "Failed to complete in trial 158\n",
      "Failed to complete in trial 159\n",
      "Failed to complete in trial 160\n",
      "Failed to complete in trial 161\n",
      "Failed to complete in trial 162\n",
      "Failed to complete in trial 163\n",
      "Failed to complete in trial 164\n",
      "Failed to complete in trial 165\n",
      "Failed to complete in trial 166\n",
      "Failed to complete in trial 167\n",
      "Failed to complete in trial 168\n",
      "Failed to complete in trial 169\n",
      "Failed to complete in trial 170\n",
      "Failed to complete in trial 171\n",
      "Failed to complete in trial 172\n",
      "Failed to complete in trial 173\n",
      "Failed to complete in trial 174\n",
      "Failed to complete in trial 175\n",
      "Failed to complete in trial 176\n",
      "Failed to complete in trial 177\n",
      "Failed to complete in trial 178\n",
      "Failed to complete in trial 179\n",
      "Failed to complete in trial 180\n",
      "Failed to complete in trial 181\n",
      "Failed to complete in trial 182\n",
      "Failed to complete in trial 183\n",
      "Failed to complete in trial 184\n",
      "Failed to complete in trial 185\n",
      "Failed to complete in trial 186\n",
      "Failed to complete in trial 187\n",
      "Failed to complete in trial 188\n",
      "Failed to complete in trial 189\n",
      "Failed to complete in trial 190\n",
      "Failed to complete in trial 191\n",
      "Failed to complete in trial 192\n",
      "Completed in 193 trials\n",
      "Failed to complete in trial 194\n",
      "Failed to complete in trial 195\n",
      "Failed to complete in trial 196\n",
      "Failed to complete in trial 197\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f6d1e6385c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# internally iterates default (prediction) model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# iterates target model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-f6d1e6385c84>\u001b[0m in \u001b[0;36mreplay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mQ_future\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mQ_future\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36_2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36_2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36_2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36_2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, env):\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=500) # appends to queue and pops at the other end\n",
    "        \n",
    "        self.gamma = 0.85\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.02\n",
    "        self.tau = .125\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model   = Sequential()\n",
    "        state_shape  = self.env.observation_space.shape\n",
    "        model.add(Dense(128, input_dim=state_shape[0], activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(self.env.action_space.n))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "            optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # take action\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    # remember history\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "        \n",
    "    def replay(self):\n",
    "        batch_size = 64\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state)[0])\n",
    "                target[0][action] = reward + Q_future * self.gamma\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "env     = gym.make(\"MountainCar-v0\")\n",
    "gamma   = 0.95\n",
    "epsilon = .95\n",
    "trials  = 1000\n",
    "trial_len = 500\n",
    "\n",
    "keep_result = []\n",
    "dqn_agent = DQN(env=env)\n",
    "steps = []\n",
    "for trial in range(trials):\n",
    "    cur_state = env.reset().reshape(1,2)\n",
    "    for step in range(trial_len):\n",
    "        # take action from current state (epsilon greedy)\n",
    "        action = dqn_agent.act(cur_state)\n",
    "        # take one step\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # reward = reward if not done else -20\n",
    "        new_state = new_state.reshape(1,2)\n",
    "        # store in memory\n",
    "        dqn_agent.remember(cur_state, action, reward, new_state, done)\n",
    "        \n",
    "        dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "\n",
    "        dqn_agent.target_train() # iterates target model\n",
    "\n",
    "        cur_state = new_state\n",
    "        if done:\n",
    "            break\n",
    "    if step >= 199:\n",
    "        keep_result.append(200)\n",
    "        print(\"Failed to complete in trial {}\".format(trial))\n",
    "        if step % 10 == 0:\n",
    "            dqn_agent.save_model(\"trial-{}.model\".format(trial))\n",
    "    else:\n",
    "        keep_result.append(step)\n",
    "        print(\"Completed in {} trials\".format(trial))\n",
    "        dqn_agent.save_model(\"success.model\")\n",
    "        \n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 192,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 183,\n",
       " 200,\n",
       " 200,\n",
       " 118,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 123,\n",
       " 200,\n",
       " 200,\n",
       " 119,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 115,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Mountaincar - old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Failed to complete in trial 0\n",
      "Failed to complete in trial 1\n",
      "Failed to complete in trial 2\n",
      "Failed to complete in trial 3\n",
      "Failed to complete in trial 4\n",
      "Failed to complete in trial 5\n",
      "Failed to complete in trial 6\n",
      "Failed to complete in trial 7\n",
      "Failed to complete in trial 8\n",
      "Failed to complete in trial 9\n",
      "Failed to complete in trial 10\n",
      "Failed to complete in trial 11\n",
      "Failed to complete in trial 12\n",
      "Failed to complete in trial 13\n",
      "Failed to complete in trial 14\n",
      "Failed to complete in trial 15\n",
      "Failed to complete in trial 16\n",
      "Failed to complete in trial 17\n",
      "Failed to complete in trial 18\n",
      "Failed to complete in trial 19\n",
      "Failed to complete in trial 20\n",
      "Failed to complete in trial 21\n",
      "Failed to complete in trial 22\n",
      "Failed to complete in trial 23\n",
      "Failed to complete in trial 24\n",
      "Failed to complete in trial 25\n",
      "Failed to complete in trial 26\n",
      "Failed to complete in trial 27\n",
      "Failed to complete in trial 28\n",
      "Failed to complete in trial 29\n",
      "Failed to complete in trial 30\n",
      "Failed to complete in trial 31\n",
      "Failed to complete in trial 32\n",
      "Failed to complete in trial 33\n",
      "Failed to complete in trial 34\n",
      "Failed to complete in trial 35\n",
      "Failed to complete in trial 36\n",
      "Failed to complete in trial 37\n",
      "Failed to complete in trial 38\n",
      "Failed to complete in trial 39\n",
      "Failed to complete in trial 40\n",
      "Failed to complete in trial 41\n",
      "Failed to complete in trial 42\n",
      "Failed to complete in trial 43\n",
      "Failed to complete in trial 44\n",
      "Failed to complete in trial 45\n",
      "Failed to complete in trial 46\n",
      "Failed to complete in trial 47\n",
      "Failed to complete in trial 48\n",
      "Failed to complete in trial 49\n",
      "Failed to complete in trial 50\n",
      "Failed to complete in trial 51\n",
      "Failed to complete in trial 52\n",
      "Failed to complete in trial 53\n",
      "Failed to complete in trial 54\n",
      "Failed to complete in trial 55\n",
      "Failed to complete in trial 56\n",
      "Failed to complete in trial 57\n",
      "Failed to complete in trial 58\n",
      "Failed to complete in trial 59\n",
      "Failed to complete in trial 60\n",
      "Failed to complete in trial 61\n",
      "Failed to complete in trial 62\n",
      "Failed to complete in trial 63\n",
      "Failed to complete in trial 64\n",
      "Failed to complete in trial 65\n",
      "Failed to complete in trial 66\n",
      "Failed to complete in trial 67\n",
      "Failed to complete in trial 68\n",
      "Failed to complete in trial 69\n",
      "Failed to complete in trial 70\n",
      "Failed to complete in trial 71\n",
      "Failed to complete in trial 72\n",
      "Failed to complete in trial 73\n",
      "Failed to complete in trial 74\n",
      "Failed to complete in trial 75\n",
      "Failed to complete in trial 76\n",
      "Failed to complete in trial 77\n",
      "Failed to complete in trial 78\n",
      "Failed to complete in trial 79\n",
      "Failed to complete in trial 80\n",
      "Failed to complete in trial 81\n",
      "Failed to complete in trial 82\n",
      "Failed to complete in trial 83\n",
      "Failed to complete in trial 84\n",
      "Failed to complete in trial 85\n",
      "Failed to complete in trial 86\n",
      "Failed to complete in trial 87\n",
      "Failed to complete in trial 88\n",
      "Failed to complete in trial 89\n",
      "Failed to complete in trial 90\n",
      "Failed to complete in trial 91\n",
      "Failed to complete in trial 92\n",
      "Failed to complete in trial 93\n",
      "Failed to complete in trial 94\n",
      "Failed to complete in trial 95\n",
      "Failed to complete in trial 96\n",
      "Failed to complete in trial 97\n",
      "Failed to complete in trial 98\n",
      "Failed to complete in trial 99\n",
      "Failed to complete in trial 100\n",
      "Failed to complete in trial 101\n",
      "Failed to complete in trial 102\n",
      "Failed to complete in trial 103\n",
      "Failed to complete in trial 104\n",
      "Failed to complete in trial 105\n",
      "Failed to complete in trial 106\n",
      "Failed to complete in trial 107\n",
      "Failed to complete in trial 108\n",
      "Failed to complete in trial 109\n",
      "Failed to complete in trial 110\n",
      "Failed to complete in trial 111\n",
      "Failed to complete in trial 112\n",
      "Failed to complete in trial 113\n",
      "Failed to complete in trial 114\n",
      "Failed to complete in trial 115\n",
      "Failed to complete in trial 116\n",
      "Failed to complete in trial 117\n",
      "Failed to complete in trial 118\n",
      "Failed to complete in trial 119\n",
      "Failed to complete in trial 120\n",
      "Failed to complete in trial 121\n",
      "Failed to complete in trial 122\n",
      "Failed to complete in trial 123\n",
      "Failed to complete in trial 124\n",
      "Failed to complete in trial 125\n",
      "Failed to complete in trial 126\n",
      "Failed to complete in trial 127\n",
      "Failed to complete in trial 128\n",
      "Failed to complete in trial 129\n",
      "Failed to complete in trial 130\n",
      "Failed to complete in trial 131\n",
      "Failed to complete in trial 132\n",
      "Failed to complete in trial 133\n",
      "Failed to complete in trial 134\n",
      "Failed to complete in trial 135\n",
      "Failed to complete in trial 136\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, env):\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=500) # appends to queue and pops at the other end\n",
    "        \n",
    "        self.gamma = 0.85\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.02\n",
    "        self.tau = .125\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model   = Sequential()\n",
    "        state_shape  = self.env.observation_space.shape\n",
    "        model.add(Dense(16, input_dim=state_shape[0], activation=\"relu\"))\n",
    "        model.add(Dense(32, activation=\"relu\"))\n",
    "        model.add(Dense(64, activation=\"relu\"))\n",
    "        model.add(Dense(self.env.action_space.n))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "            optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # take action\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    # remember history\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "        \n",
    "    def replay(self):\n",
    "        batch_size = 64\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state)[0])\n",
    "                target[0][action] = reward + Q_future * self.gamma\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "#def main():\n",
    "env     = gym.make(\"MountainCar-v0\")\n",
    "gamma   = 0.95\n",
    "epsilon = .95\n",
    "trials  = 1000\n",
    "trial_len = 500\n",
    "\n",
    "# updateTargetNetwork = 1000\n",
    "keep_result2 = []\n",
    "dqn_agent = DQN(env=env)\n",
    "steps = []\n",
    "for trial in range(trials):\n",
    "    cur_state = env.reset().reshape(1,2)\n",
    "    for step in range(trial_len):\n",
    "        # take action from current state (epsilon greedy)\n",
    "        action = dqn_agent.act(cur_state)\n",
    "        # take one step\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # reward = reward if not done else -20\n",
    "        new_state = new_state.reshape(1,2)\n",
    "        # store in memory\n",
    "        dqn_agent.remember(cur_state, action, reward, new_state, done)\n",
    "        \n",
    "        dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "\n",
    "        dqn_agent.target_train() # iterates target model\n",
    "\n",
    "        cur_state = new_state\n",
    "        if done:\n",
    "            break\n",
    "    if step >= 199:\n",
    "        keep_result2.append(200)\n",
    "        print(\"Failed to complete in trial {}\".format(trial))\n",
    "        if step % 10 == 0:\n",
    "            dqn_agent.save_model(\"trial-{}.model\".format(trial))\n",
    "    else:\n",
    "        keep_result2.append(step)\n",
    "        print(\"Completed in {} trials\".format(trial))\n",
    "        dqn_agent.save_model(\"success.model\")\n",
    "        \n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
